<html>
<head>
<title>How To: Process PISA FP2 Real-time Sounding Data</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link rel="stylesheet" type="text/css" href="http://dmg.eol.ucar.edu/css/howto.css">
</head>

<body>
<h1 class="title">How To: Process PISA FP2 Real-time Upper Air Sounding Data</h1>
<h2>Table of Contents</h2>
<div id="toc">
    <ol>
        <li><a href="#purpose">Purpose</a></li>
        <li><a href="#network">Network Information</a></li>
        <li><a href="#version">Previous Versions</a>
            <ol>
			    <li><a href="#version:PECAN_2015">2015 (PECAN)</a> - first created.</li>
            </ol>
        </li>
        <li><a href="#directory">Directory Structure</a></li>
        <li><a href="#process">Processing the Data</a>
            <ol> 
			<li><a href="#setup">Initial Processing Setup</a></li>     		
            <li><a href="#convert">Converting the Data</a></li>
            <li><a href="#autoqc">Auto QC</a></li>
 			<li><a href="#visual_qc">Visual QC</a></li>
            <li><a href="#finalize">Finalization</a></li>   
			<li><a href="#5mb-extract">5mb Extraction</a></li>      		
            </ol>
        </li>
        <li><a href="#documents">Documentation</a></li>
    </ol>
</div>
<a href="#">Top</a><hr />

<a name="purpose"></a><h2>Purpose</h2>
<div class="block">
	<p>This document contains instructions for converting Fixed PISA FP2 real-time 
radiosonde data from Greensburg, Kansas from ASCII Vaisala FLEDT format variant text 
format into the (not ESC) CLASS format for delivery to the GTS. The converter can be executed from 
the /processing directory for testing purposes or from the /production directory for real-time processing. 
For development and test, run from the /processing directory. For real-time processing, the converter 
is run every 10 minutes (on the 10mins) by a (JOSS user) cron script. 
During a production/real-time run, this converter checks for raw data deposited in 
the FTP area within the last 10 minutes (that is, since the s/w was last executed by the cron script), 
processes that data into CLASS format, generates an error log file, 
sends notification emails, and copies the generated CLASS file to a specified "GTS" directory. 
Note that copy of all input, output, and error logs are written to the /archive directory. The /archive directory contains a complete set of all the data processing. 
Another script created by the CDS S/W Engineering group takes the generated CLASS from from 
the "GTS" directory, runs the ASPEN software on the file and 
then places that output onto the GTS for immediate use by modelers.</p>
<p>
To learn more about cron jobs, search for "cron" on the internal Drupal web site, see the Documentation section at the bottom of this How To, or
go to 
<i>https://internal.eol.ucar.edu/content/pecan-sounding-processing-gts</i> .
For reference, the line in the crontab that runs this software in real-time (production) is
<br> <br><font color=green>*/10 * * * * /net/work/Projects/PECAN/upper_air/FP2_GREEN/production/software/PISA_FP2_GREEN_sounding_converter.pl >& /dev/null </font>

</p>
</div>
<a href="#">Top</a><hr />

<a name="network"></a><h2>Network Information</h2>
<div class="block">
    <ul>
    <li>The ID-Type is 999.</li>
	<li>The Platform is Unknown, Radiosonde, Vaisala RS41.</li>
    </ul>
</div>
<a href="#">Top</a><hr />

<a name="version"></a><h2>Previous Versions</h2>
<div class="block">

    <a name="version:PECAN_2015"></a><h3>PECAN (2015) - Note: This was a Fixed site during PECAN.</h3>
    <table class="version">
	<tr><th>Software:</th><td><a href="http://svn.eol.ucar.edu/websvn/listing.php?repname=dmg&path=%2Fconversions%2Fupper_air%2FPISA_FP2_GREEN%2F&#ad34e41ea792009074d0e00bfa86e6e10"</a></td></tr>
    <tr><th>Raw Data (during Real-time):</th><td>/net/iftp2/pub/incoming/pecan/FP2_Greensburg</td></tr>
    <tr><th>Final Data:</th><td>/h/eol/iss/project/pecan/data/fp2/cls</td></tr>
    </table> 


</div>
<a href="#">Top</a><hr />

<a name="directory"></a><h2>Directory Structure</h2>
<div class="block">
    <h3 class="directory_head">FP2_ARM/</h3>
    <table class="directories">
		
	    <tr><td colspan="2"><b><font color=blue>PROCESSING</font>: DEVELOPMENT AND TEST</b></td></tr>
		<tr><th>processing/</th><td>The directory where development and testing
		takes place.</td></tr>
		<tr><th>processing/archive/</th><td>The TEST directory where copies of the raw
		data, error log, and class file for each sounding are stored.</td></tr>
		<tr><th>processing/fake_FTP/</th><td>This TEST directory simulates the FTP 
		directory during the development and test phases.</td></tr>
		<tr><th>processing/fake_gts/</th><td>This TEST directory simulates the final
		data directory and is where the class files are stored.</td></tr>
	    <tr><th>processing/output/</th><td>The TEST directory where the CLASS files
		are placed after they are generated.
	    <tr><th>processing/software/</th><td>The TEST and Development directory where the software for the
	    conversion is stored.</td></tr>
	    <tr><th>processing/raw_data/</th><td>The converter moves sounding data to be 
		processed from the FTP area to this TEST raw_data directory for processing.</td></tr>

	    <tr><td colspan="2"><b><font color=red>PRODUCTION</font>: REAL-TIME PROCESSING</b></td></tr>
		<tr><th>production/</th><td>The directory where real-time processing 
		takes place. Note that the cron script runs the software from this area.</td></tr>
		<tr><th>production/archive/</th><td>The directory where copies of the raw
		data, error log, and class file for each sounding are stored.</td></tr>
	    <tr><th>production/software/</th><td>The directory where the real-time software for the
	    conversion is stored.</td></tr>
		<tr><th>production/raw_data/</th><td>The converter moves sounding data to be 
		processed from the FTP area to the raw_data directory for processing.</td></tr>
	    <tr><th>production/output/</th><td>The directory where the CLASS files
		are placed after they are generated.
    </table>
</div>
<a href="#">Top</a><hr />


<a name="process"></a><h2>Processing the Data</h2>
<div class="block"> 
    <a name="setup"></a><h3>Initial Processing Setup and Raw Data</h3>
	<ol>
	<li>During the production phase when real-time data is to be processed,
	the converter is run every 10 minutes (on the 10mins) by a cron script. For more information
	on cron scripts, see the "Documentation" section below. The converter
	software calls the ReadDataFiles function which checks the IFTP area
	<span class="directoryName">(/net/iftp2/pub/incoming/pecan/FP2_Greensburg)</span> 
	for	raw data received since the last converter run. For each file in the 
	IFTP area, the <code>stat</code> command is run and the times on the 
	files are compared to the current time. If the file is as least 1 minute 
	old and less than or equal to 11 minutes old, the file is copied to the 
	<span class="directoryName">raw_data</span> directory for processing.

	</li>
	<li>During the development/test phase, the raw data must be placed in 
	the <span class="directoryName">fake_FTP</span> directory. During the 
	production phase, the script will check for raw data in the IFTP area  
	<span class="directoryName">(/net/iftp2/pub/incoming/pecan/FP2_Greensburg)</span> 
	location so no initial setup is required. In each case, data must be 
	less than 10 minutes old, so for testing purposes, be sure to "touch" the 
	files in the <span class="directoryName">fake_FTP</span> directory; 
	otherwise, they may be too "old" to be processed and the code will ignore the "old" files.</li>
	<li>Check the assumptions made in the script regarding things such 
	as file names and locations. Search for "HARDCODED" in the processing 
        software for all hardcoded values. <font color=red>These should be carefully checked
        before running the software.</font></li>

	<p><i>Assumptions for PECAN 2015 PISA FP2 in Greensburg, KS:</i>
    	<ul>
		<li>Raw data files were ascii text files in Vaisala FLEDT format variant.
The file contains header info on lines 1-40. Actual data starts on line 41. That the incoming raw data are located in the /net/iftp2/pub/incoming/pecan/FP2_Greensburg  directory. </li>

		<li>The converter expects raw data filenames in the following format: 
		UMBC_RS41_yyyymmdd_hhmmUT.dat where yyyy = year, mm = month, 
                dd = day, hh=hour, mm = minute.  </li>

                <li> That the outgoing CLASS soundings created by this s/w should be placed in 
                     the /h/eol/iss/project/pecan/data/fp2/cls directory.</li>

                <li> That the following directories exist: ../output, ../archive. </li>

    	</ul>
    </p>

	</li>         
    </ol>  

    <a name="convert"></a><h3>Converting the Data</h3>
 	<p class="note">During the production phase, the converter is automatically executed every
	10 minutes by a (JOSS user) cron script. To learn more about how to do that, see the comments in the Purpose 
        section of this document. This "Converting the Data" section only applies to the development and 
	testing phase where the user is executing the s/w at the command line. </p>
	<p class="note">This step runs Perl code and should work on basically any
	machine. However, to run the autoQC and any other processing/data prep done
	by the build.xml (Ant) file, you must run on any machine with the proper
	Ant and Java setup, such as tikal. Note that during real-time production execution
        autoQC was NOT done. In fact, no checking of any of the converted CLASS data was
        done during real-time production. The data were simply converted to CLASS and sent
        to the "GTS" directory where ASPEN was executed to check and create the GTS message.</p>       
	<p>Converting Fixed PISA FP2 Greensburg High Resolution Radiosonde data from ASCII text format into
	the CLASS format consists of the following steps.</p>

	<ol>	
	<li>Change to the <span class="directoryName">software</span> directory.</li>
	<li>Edit the <span
	class="softwareName">PISA_FP2_GREEN_sounding_converter.pl</span>
	script, as needed.
	<ul>
		<li><font color=red>Search for "HARD-CODED" to find and 
		change the hard-coded project-specific values in the script to 
		be correct for your project. There are several of these including
                the email addresses of those who will receive messages. Check
                these all carefully.</font>  
                </li>

                <li><font color=red>NOTE: There are numerous checks in the converter code since real-time
	   data processing must assume that the raw data files conform to clearly
	   defined expectations. This converter checks for many discrepancies.
           Please see the header in the software to see the complete and up-to-date
           listing of assumptions and checks. </font></li>
	        </li>

	</ul>
	</li>

	<li>Run the <span class="softwareName">PISA_FP2_GREEN_sounding_converter.pl</span> 
	script. This will convert the raw_data to the CLASS format, create error log files, and send emails to specified users. A copy of all raw data, output CLASS files, and error logs are copied to the /archive directory so a complete set of all processed data can be found there. </li> 
	<li>NOTE: The following steps are optional but can be helpful in testing. Run the format checker using the ant command:
    <p class="code">ant check-format-ESC</p></li>
	<li>Check the log file (generated by the format checker) in the <span
	class="directoryName">output</span> directory to determine if any format
	issues need to be addressed.</li>
	</ol>


<a name="autoqc"></a><h3>Auto QC and Visual QC</h3>
	<p class="note">No Autoqc or Visual QC is required for the real-time processing of this data.</p>


<a name="finalize"></a><h3>Finalization</h3>
<p class="note">It has not yet been determined if these data will be loaded into
CODIAC, so the following is for informational purposes only.</p>
	<p>After the visual QC is completed, the data set is ready to be finalized
	(i.e, prep'd for CODIAC).  
       <ol>
		 <li>Update this "How To" document to indicate the latest project
		 this conversion was executed for and include any notes about upgrades
		 made specifically for that project, as required. A copy of this
		 document is generally found in the <span
		 class="directoryName">docs</span> directory. Place a copy of the
		 updated doc in <span
		 class="directoryName">/net/web/dmg/html/software/conversions/upper_air/PISA_FP2_GREEN</span>
		 directory. The s/w repository page points to this doc in that web
		 location, so this must be updated.  The s/w repository page is located
		 <a
		 href="https://internal.eol.ucar.edu/node/519"
		 target='_top'><b>here</b></a>.</li>

		 <li>Update the dataset description (or EMDAC) document for this
		 conversion. Work with the scientific staff to create an EMDAC
		 document. Generally, start with an existing "similar" document and
		 simply update it for this project and dataset.  Generally, a copy of
		 the EMDAC doc can be found in the <span
		 class="directoryName">docs</span> area.</li>

		<li>The next processing step is to create day files that can/will be
		loaded into the EMDAC/CODIAC database, along with the EMDAC dataset
		description document.  The dayfiles creation step will generate day
		files sorted by nominal release date followed by station location as
		required by CODIAC. It's very important that the output dayfiles be in
		this expected sort order so that CODIAC can access all the soundings
		within a single dayfile. Do the following steps to create the day
		files.</li>
    <ul>
	   <li>Ensure that you are in the same (top) directory as the build.xml
	   file. Create the day files using the ant command:</p>
	   <p class="code">ant dayfiles</p> <p>This will create a file for each day
	   where at least one sounding exists in the <span
	   class="directoryName">dayfiles</span> directory or whichever directory
	   is specified as the output directory in the build.xml file. If this
	   dataset is to be put online "as is," these are the dayfiles to load into
	   CODIAC.</li>
       </li>
    </ul>
    </ol>


<a name="5mb-extract"></a><h3>5mb Extraction</h3>
	<p>If the converted soundings are also going to be placed into a 5mb
	composite, the soundings need to have the proper 5mb pressure level
	soundings generated.  This is done through the following steps:</p>
    <ol>
        <li>Generate the 5mb pressure level data files using the ant command:
            <p class="code">ant 5mb-extract</p>
			This will generate a 5 mb sounding file for each sounding in the
			<span class="directoryName">final</span> directory and place
			it in the <span class="directoryName">5mb</span>.  It will also run
			some final checks to make sure the format is correct. Beware that
			the file directories listed in the build.xml file are what you
			expect and want.   	        
        </li>
    </ol>
	<p>The generated 5mb data files will then be available when the composite
	is generated.</p>

</div>
<a href="#">Top</a><hr>

<a name="documents"></a><h2>Documentation</h2>
<p>The following are a list of documents that may help with the conversion or
are related to the raw data.</p>
<ul>
    <li><a href="https://internal.eol.ucar.edu/content/cron-jobs-crontab-joss-user-and-cron-scripts-relating-hpcn-and-npn-data-ingest">Cron Jobs, Crontab, joss user, and cron scripts relating to HPCN and NPN Data ingest</a>: Information on Executing, Location, etc. for Joss User Cron Scripts.</li>
	<li><a href="/software/tools/upper_air/autoqc">How To: AUTO QC Sounding Data</a>:  The instructions for dealing with the AUTO QC program.</li>
	<li><a href="/software/tools/upper_air/esc_format_checker">How To: ESC Format Checker</a>:  The instructions and API for working with the ESC format checker program.</li>
    <li><a href="#">How To: Process PISA FP2 Real-time Sounding Data</a>:  This document.</li>

</ul>
<a href="#">Top</a><hr>

<!-- NOTE: Mozilla gives local time; Chrome gives UTC time -->
<script type="text/javascript">
    document.write("Last Updated: " + document.lastModified);
</script>
<hr />
<br />

</body>
</html>
