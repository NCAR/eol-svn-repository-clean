<html>
<head>
<title>How To: Process Singapore GRAW Sounding Data</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link rel="stylesheet" type="text/css" href="http://dmg.eol.ucar.edu/css/howto.css">
</head>

<body>
<h1 class="title">How To: Process Singapore GRAW Upper Air Sounding Data</h1>
<h2>Table of Contents</h2>
<div id="toc">
    <ol>
        <li><a href="#purpose">Purpose</a></li>
        <li><a href="#network">Network Information</a></li>
        <li><a href="#version">Previous Versions</a>
            <ul>			
                <li><a href="#version:DYNAMO_2011_GRAW">2011 (DYNAMO GRAW)</a> - Created for DYNAMO 2011</li>
                <li><a href="#version:DYNAMO_2011)_CSV">2011 (DYNAMO CSV)</a> - Created for DYNAMO 2011</li>
            </ul>
        </li>
        <li><a href="#directory">Directory Structure</a></li>
        <li><a href="#process">Processing the Data</a>
            <ol>
			<li><a href="#setup">Initial Processing Setup</a></li> 
            <li><a href="#convert">Converting the Data</a></li>
            <li><a href="#autoqc">Auto QC</a></li>
			<li><a href="#visual_qc">Visual QC</a></li>
            <li><a href="#finalize">Finalization</a></li>   
			<li><a href="#5mb-extract">5mb Extraction</a></li>  
            </ol>
        </li>
        <li><a href="#documents">Documentation</a></li>
    </ol>
</div>
<a href="#">Top</a><hr />

<a name="purpose"></a><h2>Purpose</h2>
<div class="block">
	<p>This document contains instructions for converting Singapore upper air sounding data from the GRAW tab-delimited ASCII format into the EOL Sounding Composite (ESC) format.</p>
</div>
<a href="#">Top</a><hr />                                        

<a name="network"></a><h2>Network Information</h2>
<div class="block">
    <ul>
    <li>The ID-Type is 99.</li>
    <li>The Platform Id is 415 (Radiosonde, Vaisala RS92-SGP).</li>
</ul>
</div>
<a href="#">Top</a><hr />

<a name="version"></a><h2>Previous Versions</h2>
<div class="block">
 
    <a name="version:DYNAMO_2011_GRAW"></a><h3>DYNAMO GRAW (2011)</h3>
    <table class="version">
	<tr><th>Software:</th><td><a
	href="http://svn.eol.ucar.edu/websvn/listing.php?repname=dmg&path=%2Fconversions%2Fupper_air%2FSingapore%2Ftags%2FDYNAMO_2011%2F#_conversions_upper_air_Singapore_tags_DYNAMO_2011_">http://svn.eol.ucar.edu/svn/dmg/conversions/upper_air/Singapore/tags/DYNAMO 2011</a></td></tr>
    <tr><th>Raw Data:</th><td>/net/work/Projects/dynamo/upper_air/Singapore/2011-12_processing/GRAW_processing/raw_data</td></tr>
    <tr><th>Final Data:</th><td>/net/work/Projects/dynamo/upper_air/Singapore/2011-12_processing/GRAW_processing/dayfiles</td></tr>
    </table>
    
	<a name="version:DYNAMO_2011_CSV"></a><h3>DYNAMO CSV (2011)</h3>
    <table class="version">
	<tr><th>Software:</th><td><a
	href="http://svn.eol.ucar.edu/websvn/listing.php?repname=dmg&path=%2Fconversions%2Fupper_air%2FSingapore%2Ftags%2FDYNAMO_2011%2F#_conversions_upper_air_Singapore_tags_DYNAMO_2011_">http://svn.eol.ucar.edu/svn/dmg/conversions/upper_air/Singapore/tags/DYNAMO 2011</a></td></tr>
    <tr><th>Raw Data:</th><td>/net/work/Projects/dynamo/upper_air/Singapore/2011-12_processing/csv_processing/raw_data</td></tr>
    <tr><th>Final Data:</th><td>/net/work/Projects/dynamo/upper_air/Singapore/2011-12_processing/csv_processing/dayfiles</td></tr>
    </table>

</div>
<a href="#">Top</a><hr />

<a name="directory"></a><h2>Directory Structure</h2>
<div class="block">
    <h3 class="directory_head">Singapore/2011-12_processing/GRAW_processing</h3>
    <table class="directories">
		<tr><th>5mb/</th><td>The directory where the extracted 5mb pressure
		sounding files are stored.</td></tr>
		<tr><th>build/</th><td>The auto-generated directory for the compiled
		Java classes.</td></tr>
		<tr><th>dayfiles/</th><td>The directory where the generated day files
		are stored. These are the final processed data files that will be
		loaded into the database and put online. </td></tr>
	    <tr><th>docs/</th><td>The directory containing documentation about the
	    processing and the data.</td></tr> 
		<tr><th>final/</th><td>The directory where the QC'ed files are placed
		once they have been created.</td></tr> 
		<tr><th>logs/</th><td>The directory where the error/check files from
		the QC are placed.</td></tr> 
		<tr><th>output/</th><td>The directory where the CLASS files are put
		after they are generated.</td></tr> 
	    <tr><th>raw_data/</th><td>The directory where the raw data is
	    stored.</td></tr>
		<tr><th>software_source/</th><td>The directory where the software for
		the conversion is stored.</td></tr>
	    <tr><th>src/</th><td>Unused directory.  Required for AutoQC to run.</td></tr>
    </table>
</div>
<a href="#">Top</a><hr />

<a name="process"></a><h2>Processing the Data</h2>
<div class="block">
    <a name="setup"></a><h3>Initial Processing Setup</h3>
	<ol>	
	<li><p>Copy the raw data into the <span
	class="directoryName">raw_data</span> directory.  Run dos2unix on the MS-DOS text files.</p></li>               
    </ol>

    <a name="convert"></a><h3>Converting the Data</h3>
	<p class="note">This step runs Perl code and should work on basically any
	machine. However, to run the autoQC and any other processing/data prep done
	by the build.xml (Ant) file, you must run on any machine with the proper
	Ant and Java setup, such as tikal.</p>    
	<p>Converting the Singapore radiosonde data from GRAW format into the ESC
	format consists of the following steps.</p>

	<ol>                                  
	<li><p>Change to the <span class="directoryName">software</span> directory.</p></li>
	<li><p>Edit the <span
	class="softwareName">GRAW_Radiosonde_Converter.pl</span> script.</p> 
       	<p><i>For DYNAMO</i>:</p>
	    <ul> 
			<li><p>Code was added to identify the last header line since the
			data began on different lines in different files (due to
			inconsistent blank lines in the header).</p></li>
			<li><p>The Latitude and Longtitude information was taken from the
			csv header and hard-coded into the converter.</p></li>
			<li><p>Files names were of the form:<br />
			<blockquote>
			201112250000107064_UPP_RAW_48698_2011122423.txt<br />
			YYYYMMDDHHmmRRRRRR_UPP_RAW_48698_YYYYMMDDHH.txt<br />
			</blockquote>
			where the
			first block is the nominal date/time plus radiosonde serial
			number, 48698 is the WMO site ID, and the last block is the
			release date/time.</p></li>
			<li><p>The nominal and release date/time and the radiosonde ID
			information were obtained from the raw data file name.</p></li>
			<li><p class="BEWARE">BEWARE: Most of the raw data files had
			altitude data with units in feet, but 23 files had units in meters.
			A command line option [--convert_alt] was added so that converting
			feet to meters was optional.  The 23 files with units in meters
			were put in a separate directory and these data were processed,
			format checked and autoqc'd separately. The <span
			class="directoryName">/output</span> and <span
			class="directoryName">/final</span> directory contents were moved
			aside into temporary directories while the raw data with units in
			feet were processed.  After format checking and autoqc on the files
			with units in feet, the files were combined in the <span
			class="directoryName">/output</span> and <span
			class="directoryName">/final</span> directories.</p></li>
			<li><p>Two of the raw data files required a correction factor for
			the altitude due to incorrect surface altitude being used.  Scot L.
			provided the correction factors.  A default factor of "0" was used
			to compensate for the remainder of the files.</p></li>
			<li><p>Many of the raw data files contained descending data (the
			sonde had started to fall) that needed to be removed.  Code was
			added to load each record into an array, then the array was
			reversed and each record was tested for ascent rate less than zero.
			If ascent rate was less than zero, the record was removed from the
			array.</p></li>
			<li><p>At the science staff's request, code was added to set the
			dew point to missing any time that the temperature was missing.
			The dew points were invalid when the temperatures were
			missing.</p></li>
			<li><p>At the science staff's request, code was added to set the
			dew point to missing any time that the RH (humidity) was missing.
			The dew points were invalid when the temperatures were
			missing.</p></li>
			<li><p class="BEWARE">BEWARE: For three files, the science staff
			requested that code be removed after a particular point due to the
			sonde falling or icing conditions.  This was done
			manually.</p></li>
	    </ul>
	</li>
	<li><p>Change hard-coded values for project-specific items such as
		Project, Network, State, etc.</p></li>
	</li>
    <li><p>Verify that the converted data columns match the required ESC
format (<a href="http://www.eol.ucar.edu/about/our-organization/cds/dmg/dmg-internal/dmg-documentation/tutorial/sounding-processing-and-composite-generation/appendix-esc-format-description">see
example</a>).</p></li>	
	<li><p>Run the <span
	class="softwareName">GRAW_Radiosonde_Converter.pl</span> script.
	This will convert the data to the ESC format.</p></li>
	
	<li><p>Run the format checker using the ant command:</p>
    <p class="code">ant check-format-ESC</p></li>
	<li><p>Check the log file in the <span class="directoryName">output</span>
	directory to determine if any format issues need to be addressed before
	proceeding with AutoQC.</p></li>
	</ol>

<a name="autoqc"></a><h3>Auto QC</h3>
	<p class="note">This step works best on tikal, but can be done on any
	machine with the proper Ant and Java setup.</p>

	<p>These steps execute the automatic QC on the processed files in the <span
	class="directoryName">output</span> directory, generate log files in the
	<span class="directoryName">logs</span> directory, and place the QC'ed data
	files into the <span class="directoryName">final</span> directory, as
	specified by the <span class="softwareName">build.xml</span> file.  After
	the QC processing has completed, the <span class="softwareName">ant
	autoqc</span> command runs the format checker on the QC'ed files. Here are
	the steps to run the sounding Automatic Quality Control Processing:</p>
    <ol>
	   <li><p>Stay in/Change to the top level processing directory where the Ant
	   <span class="softwareName">build.xml</span> file is located.</p></li>
	   <li><p>Check the <span class="softwareName">build.xml</span> file for the
	   <code>autoqc</code> target for the following:</p>
           <ol>
			   <li><p>A command to copy the properties file to the build
			   directory. There is typically a copy of the autoqc properties
			   file (e.g., "us_plains_autoqc.properties") in the software
			   directory.</p></li>   		   
			   <li><p>The java command(s) will be executed on the expected data in
			   the expected locations (i.e., ensure that the directory names in
			   the build.xml file are correct and what you want.)</p></li>
			   <li><p>You have updated the project name in the build.xml,
			   if included in the build.xml file.</p></li>
		   </ol>	
       <li><p>Perform the auto QC by executing the ant command:</p>
	       <p class="code">ant autoqc</p></li>  
	</ol>

	

<a name="visual_qc"></a><h3>Visual QC</h3>
	<p>Once the auto QC is completed, email the scientific staff (i.e., Scot
	Loehrer) so that they can perform a visual QC on the data and give final
	approval of the processed data set, as required. Note that the visual qc is
	not performed on all sounding datasets.</p>


<a name="finalize"></a><h3>Finalization</h3>
	<p>After the visual QC is completed, the data set is ready to be finalized
	(i.e, prep'd for CODIAC).  
    <ol>
		 <li><p> Update this "How To" document to indicate the latest project
		 this conversion was executed for and include any notes about upgrades
		 made specifically for that project, as required. A copy of this
		 document is generally found in the <span
		 class="directoryName">/docs</span> directory. Place a copy of the
		 updated doc in <span
		 class="directoryName">/net/web/dmg/html/software/conversions/upper_air/Singapore
		 </span> directory. The s/w repository page points to this doc in that
		 web location, so this must be updated.  The s/w repository page is
		 located <a
		 href="http://www.eol.ucar.edu/about/our-organization/cds/dmg/dmg-internal/dmg-documentation/encyclopedia/repository-dmg-subversion-listing"
		 target='_top'><b>here</b></a>. </p></li>

		 <li><p>Update the dataset description (or EMDAC) document for this
		 conversion. Work with the scientific staff to create an EMDAC
		 document. Generally, start with an existing "similar" document and
		 simply update it for this project and dataset.  Generally, a copy of
		 the EMDAC doc can be found in the <span
		 class="directoryName">/docs</span> area.</p></li>

		 <li><p>The next processing step is to create day files that can/will
		 be loaded into the EMDAC/CODIAC database, along with the EMDAC dataset
		 description document.  The dayfiles creation step will generate day
		 files sorted by nominal release date followed by station location as
		 required by CODIAC. It's very important that the output dayfiles be in
		 this expected sort order so that CODIAC can access all the soundings
		 within a single dayfile. Do the following steps to create the day
		 files.</p></li>
		 <ol>
		 <li><p>Ensure that you are in the same (top) directory as the
		 build.xml file. Create the day files using the ant command:</p> <p
		 class="code">ant dayfiles</p> <p>This will create a file for each day
		 where at least one sounding exists in the <span
		 class="directoryName">dayfiles</span> directory or whichever directory
		 is specified as the output directory in the build.xml file. If this
		 dataset is to be put online "as is", these are the dayfiles to load
		 into CODIAC.</p></li>
	     </ol>
    </ol>


<a name="5mb-extract"></a><h3>5mb Extraction</h3>
	<p>If the converted soundings are also going to be placed into a 5mb
	composite, the soundings need to have the proper 5mb pressure level
	soundings generated.  This is done through the following steps:</p>
    <ol>
        <li><p>Generate the 5mb pressure level data files using the ant command:</p>
            <p class="code">ant 5mb-extract</p>
			<p>This will generate a 5 mb sounding file for each sounding in the
			<span class="directoryName">final</span> directory and place
			it in the <span class="directoryName">5mb</span> directory.  It will also run
			some final checks to make sure the format is correct. Beware that
			the file directories listed in the build.xml file are what you
			expect and want.</p></li>
    </ol>
	<p>The generated 5mb data files will then be available when the composite
	is generated.</p>

	</div>
<a href="#">Top</a><hr>

<a name="documents"></a><h2>Documentation</h2>
<p>The following are a list of documents that may help with the conversion or
are related to the raw data.</p>
<ul>
	<li><a href="/software/tools/upper_air/autoqc">How To: AUTO QC Sounding Data</a>:  The instructions for dealing with the AUTO QC program.</li>
	<li><a href="/software/tools/upper_air/esc_format_checker">How To: ESC Format Checker</a>:  The instructions and API for working with the ESC format checker program.</li>
    <li><a href="#">How To: Process Singapore GRAW Sounding Data</a>:  This document.</li>

</ul>
<a href="#">Top</a><hr>      

<p class="foot">Last Updated: 17 August 2012 - Linda Echo-Hawk</p>
</body>
</html>
